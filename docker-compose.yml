version: '3.8'

services:
  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_USER: sapid
      POSTGRES_PASSWORD: sapid
      POSTGRES_DB: sapid
    volumes:
      - ./backend/scripts/check_pg_version.sh:/docker-entrypoint-initdb.d/check_pg_version.sh:ro
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $$POSTGRES_USER"]
      interval: 10s
      timeout: 5s
      retries: 5

  chroma:
    image: ghcr.io/chroma-core/chroma:latest
    environment:
      IS_PERSISTENT: "TRUE"
    volumes:
      - chroma_data:/chroma
    healthcheck:
      test: ["CMD", "curl", "-f", "http://chroma:8000/heartbeat"]
      interval: 10s
      timeout: 5s
      retries: 5

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_models:/root/.ollama
    command: ["serve"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 5s
      retries: 3

  backend:
    build:
      context: ./backend
      dockerfile: docker/Dockerfile
    depends_on:
      - postgres
      - chroma
      - ollama
    environment:
      POSTGRES_URL: postgresql://sapid:sapid@postgres:5432/sapid
      CHROMA_URL: http://chroma:8000
      OLLAMA_URL: http://ollama:11434
      OLLAMA_CHAT_MODEL: tinyllama:latest
      OLLAMA_EMBED_MODEL: nomic-embed-text
    ports:
      - "8001:8001"
    volumes:
      - ./backend:/app
      - ./frontend:/frontend

  frontend:
    build: ./frontend
    depends_on: [backend]
    ports:
      - "3000:80"
    healthcheck:
      test: ["CMD","curl","-f","http://localhost/"]
      interval: 30s
      timeout: 5s
      retries: 3

  frontend-build:
    image: node:20-alpine
    working_dir: /workspace
    volumes: [ "./frontend:/workspace" ]
    command: ["sh","-c","npm ci && npm run build"]
    profiles: [ "build" ]


  whisper:
    build:
      context: ./docker/voice
      dockerfile: Dockerfile.whisper
    ports:
      - "9000:9000"
    profiles:
      - voice

  tts:
    build:
      context: ./docker/voice
      dockerfile: Dockerfile.tts
    ports:
      - "9001:9001"
    profiles:
      - voice


volumes:
  postgres_data: {}
  chroma_data: {}
  ollama_models: {}
